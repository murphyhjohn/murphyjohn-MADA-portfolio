---
title: "ml-models-exercise"
author: "Murphy John"
editor: visual
---

# Setup

```{r}
# load packages
library(dplyr)
library(ggplot2)
library(tidymodels)
```

```{r}
# set seed
rdmseed <- 1234
set.seed(rdmseed)
```

```{r}
# load data 
dat <- readRDS(here::here("fitting-exercise/data/mavoglurant-processed.rds"))

## make sex and race numeric
dat$sex <- as.numeric(dat$sex)
dat$race <- as.numeric(dat$race)
```

# Data processing

To find out what the values used to encode race stand for, I searched the provided manuscript. In the Clinical data subsection of Methods, the authors write "The IV data used to optimize the disposition model (Study 1) were previously described by Wendling et al". I opened the article that was referenced and located the Table 1 which described the data. The data that we are using is called, in this reference, Study A2121. The race variable distribution is reported as Caucasian (61.7), Black (30), Native American (1.7) and Other (6.7). We can cross-reference these percentages with our data (see below) and see that 1=Caucasian, 2=Black, 7=Native American, and 88=Other.

```{r}
prop.table(table(x=dat$race))
```

```{r}
# combine categories 7 and 88 of the race variable
dat$race_recode <- case_when(
  dat$race %in% c(7, 88) ~ 3,
  TRUE ~ as.numeric(dat$race)
)
```

# EDA

```{r}
# get continuous variables
cor <- cor(dat %>% select(Y,age,wt,ht))

# correlation plot
corrplot::corrplot(cor, method='number')
```

# Feature engineering

```{r}
# determine units of wt and ht
summary(dat$wt)
## median weight is 82.1, min is 56.6, max is 115.3
## it seems logical to assume wt is measured in kg
## the Table 1 of the reference mentioned previously, reports weight in 
## kg with median (range) 82.8 (56.6–115.3) which matches

summary(dat$ht)
## median height is 1.77, min is 1.52, max is 1.93
## it seems logical to assume ht is measured in meters
## the Table 1 of the reference mentioned previously does not report height,
## but it does report bmi. we can compute bmi based on our confirmed weight
## measurments and our assumed height measurements and see if we get similar
## values for bmi

# create bmi variable
dat$bmi <- dat$wt / (dat$ht)^2

# summarize new bmi variable
summary(dat$bmi)
## the median bmi of our created variable is 26.38, min is 18.69, max is 32.21
## the median (range) of the bmi variable reported in the reference Table 1 is
## 26.5 (18.7–32.2). Thus, our calculation is consistent with the reference
```

# Model building

```{r}
# set seed
set.seed(rdmseed)
```

## linear model

```{r}
# fit model
linear_mod <- linear_reg() %>%
  fit(
    Y ~ dose + age + sex + race_recode + bmi, 
    data=dat
    )

# generate predictions
linear_pred <- predict(linear_mod, new_data=dat)

# merge predictions to data
dat$pred_linear <- linear_pred$.pred
```

```{r}
# get rmse
dat %>%
  rmse(truth = Y, estimate = pred_linear)
```

RMSE of the linear model is 624.

```{r}
# plot observed vs fitted
ggplot(dat) +
  geom_point(aes(x=Y, y=pred_linear)) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  scale_x_continuous(limits=c(0,6000)) +
  scale_y_continuous(limits=c(0,4000))
```

## lasso regression

```{r}
# set seed
set.seed(rdmseed)

# recipe
dat_rec <- recipe(
  Y ~ dose + age + sex + race_recode + bmi,
  data=dat
  ) %>%
  step_normalize(all_numeric(), -all_outcomes())

# specify and fit models
lasso_spec <- linear_reg(penalty = 0.1, mixture = 1) %>%
  set_engine("glmnet")

wf <- workflow() %>%
  add_recipe(dat_rec) 

lasso_fit <- wf %>%
  add_model(lasso_spec) %>%
  fit(data=dat)

# generate predictions
lasso_pred <- predict(lasso_fit, new_data = dat)

# merge predictions to data
dat$pred_lasso <- lasso_pred$.pred

# check variable selection
lasso_fit %>% extract_fit_parsnip() %>% tidy()
```

```{r}
# get rmse
dat %>%
  rmse(truth = Y, estimate = pred_lasso)
```

RMSE of the lasso regression is 624. The lasso regression and the full linear model produce almost identical predictions. The lasso penalty of 0.1 is pretty small, so it likely isn't shrinking the coefficients much. Based on the lasso variable selection, `sex` is the only variable with a coefficient of zero. This means that the model is behaving similarly to the full linear model.

```{r}
# plot observed vs fitted
ggplot(dat) +
  geom_point(aes(x=Y, y=pred_lasso)) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  scale_x_continuous(limits=c(0,6000)) +
  scale_y_continuous(limits=c(0,4000))
```

## random forest

```{r}
# set seed
set.seed(rdmseed)

# specify and fit models
rf_spec <- 
    rand_forest() %>% 
    set_mode("regression") %>% 
    set_engine("ranger", seed = rdmseed)

rf_fit <- rf_spec %>%
  fit(Y ~ dose + age + sex + race_recode + bmi, data=dat)

# generate predictions
rf_pred <- predict(rf_fit, dat)

# merge predictions to data
dat$pred_rf <- rf_pred$.pred
```

```{r}
# get rmse
dat %>%
  rmse(truth = Y, estimate = pred_rf)
```

RMSE of the random forest is 416 (361 when also including ht and wt).

```{r}
# plot observed vs fitted
ggplot(dat) +
  geom_point(aes(x=Y, y=pred_rf)) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  scale_x_continuous(limits=c(0,6000)) +
  scale_y_continuous(limits=c(0,4000))
```

# Tuning the models

## lasso tuning

```{r}
set.seed(rdmseed)

tune_lasso_grid <- tibble(penalty = 10^seq(-5, 2, length.out = 50))

tune_lasso_spec <- linear_reg(penalty = tune()) %>%
  set_engine("glmnet")

tune_rec <- recipe(Y ~ dose + age + sex + race_recode + bmi, data = dat)

tune_lasso_wf <- workflow() %>%
  add_model(tune_lasso_spec) %>%
  add_recipe(tune_rec)
```

```{r}
lasso_tune_results <- tune_grid(
  tune_lasso_wf,
  resamples = apparent(dat),
  grid = tune_lasso_grid,
  metrics=metric_set(yardstick::rmse)
)

lasso_tune_results_metrics <- as.data.frame(lasso_tune_results$.metrics)
```

```{r}
ggplot(lasso_tune_results_metrics, aes(penalty, y = .estimate)) +
  geom_line(size=1) +
  scale_x_log10()
```

## rf tuning

```{r}
tune_rf_grid <- grid_regular(
  mtry(range = c(1, 7)),
  min_n(range = c(1, 21)),
  levels = 7
  )

tune_rf_spec <- rand_forest(
  mtry=tune(), 
  min_n=tune(), 
  trees=300
  ) %>% 
  set_mode("regression") %>%
  set_engine("ranger", seed=rdmseed) 

tune_rf_wf <- workflow() %>% add_model(tune_rf_spec) %>% add_recipe(tune_rec)
```

```{r}
rf_tune_result <- tune_rf_wf %>% 
  tune_grid(
    resamples=apparent(dat), 
    grid=tune_rf_grid, 
    metrics=metric_set(yardstick::rmse)
    )

rf_tune_result_metrics <- as.data.frame(rf_tune_result$.metrics)
```

```{r}
ggplot(rf_tune_result_metrics, aes(x=mtry, y = min_n, fill = .estimate)) +
  geom_tile()
```

